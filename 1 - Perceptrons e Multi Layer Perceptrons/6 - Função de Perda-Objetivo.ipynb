{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6 - Função de Perda/Objetivo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wACwWw-sdc9"
      },
      "source": [
        "# Função de Perda/Objetivo\n",
        "\n",
        "A escolha da função objetivo está diretamente relacionada ao problema sendo resolvido. Assim como a camada de saída da rede.\n",
        "\n",
        "Os principais problemas resolvidos por redes neurais são: Classificação e regressão.\n",
        "\n",
        "No caso de regressão, para cálculo de preço de imóveis por exemplo, podemos definir uma função objetivo, ou função de perda da seguinte forma:\n",
        "\n",
        "    Sendo y o valor real e y' o valor predito pela rede neural:\n",
        "    \n",
        "    Função de perda = |y' - y|     -> Distância absoluta (Perda L1)\n",
        "    ou\n",
        "    Função de perda = |y' - y|²    -> Distância quadrática (Mean Squared Error - MSE)\n",
        "\n",
        "Dessa forma, o objetivo é minimizar a distâcia entre os dois valores. Já para problemas de classificação, uma função bastante utilizada é a **Cross-Entropy**, na qual vai atribuir pesos para os erros e acertos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aELItS8Maz5v"
      },
      "source": [
        "### Função de perda/objetivo para Classificação\n",
        "\n",
        "#### Preparação dos dados e da rede neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_0JyC9mpx_y"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from sklearn import datasets"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF1o56J3ytA5",
        "outputId": "e77679dc-f738-4a98-be9c-759294053bd5"
      },
      "source": [
        "# definição do device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHHP5t2Ry1Pk",
        "outputId": "13e85d76-2a0f-4fbc-84aa-047ab2ebdb3a"
      },
      "source": [
        "# definição dos dados\n",
        "# dataset de vinhos do sklearn\n",
        "\n",
        "vinhos = datasets.load_wine()\n",
        "\n",
        "dados = vinhos.data\n",
        "dados_nomes = vinhos.feature_names\n",
        "\n",
        "labels = vinhos.target\n",
        "labels_nomes = vinhos.target_names\n",
        "\n",
        "print(\"Formato dados:\", dados.shape)\n",
        "print(\"Formato labels:\", labels.shape)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato dados: (178, 13)\n",
            "Formato labels: (178,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "pDKv6lbo0uIk",
        "outputId": "85798a90-23f6-4c35-88aa-31cc1d0275f4"
      },
      "source": [
        "vinhos_df = pd.DataFrame(data=dados, columns=dados_nomes)\n",
        "vinhos_df.head()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alcohol  malic_acid   ash  ...   hue  od280/od315_of_diluted_wines  proline\n",
              "0    14.23        1.71  2.43  ...  1.04                          3.92   1065.0\n",
              "1    13.20        1.78  2.14  ...  1.05                          3.40   1050.0\n",
              "2    13.16        2.36  2.67  ...  1.03                          3.17   1185.0\n",
              "3    14.37        1.95  2.50  ...  0.86                          3.45   1480.0\n",
              "4    13.24        2.59  2.87  ...  1.04                          2.93    735.0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXU9gtnNXmhA"
      },
      "source": [
        "# Definição da rede neural\n",
        "\n",
        "class WineClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, out_size):\n",
        "        super(WineClassifier, self).__init__()\n",
        "        self.hidden = nn.Linear(input_size, hidden_size)    ## Camada hidden com \n",
        "        self.relu = nn.ReLU()                               ## Ativação ReLU\n",
        "        self.out = nn.Linear(hidden_size, out_size)         ## Saída linear\n",
        "        self.softmax = nn.Softmax()                         ## softmax para transformar em probabilidades\n",
        "\n",
        "    def forward(self, dados):\n",
        "        feature = self.relu(self.hidden(dados))     ## feature é a ativação ReLU da camada hidden\n",
        "        output = self.softmax(self.out(feature))    ## softmax da camada de saída recebendo feature\n",
        "        return output"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O38oZPt-ZVyP",
        "outputId": "7a102810-43b2-443a-fe02-791df287ed9f"
      },
      "source": [
        "input_size = dados.shape[1]  ## quantidade de features do dataset\n",
        "hidden_size = 32            ## quantidade julgada necessária para o problema (hiperparametro)\n",
        "output_size = len(labels_nomes) ## quantidade de tipos de vinhos\n",
        "\n",
        "print(\"Input_size:\", input_size)\n",
        "print(\"Hidden_size:\", hidden_size)\n",
        "print(\"Output_size:\", output_size)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input_size: 13\n",
            "Hidden_size: 32\n",
            "Output_size: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYG_uo4LaNxP",
        "outputId": "b63bb379-cb80-4404-efd0-cf9e91b4b0ce"
      },
      "source": [
        "# Criação da rede:\n",
        "\n",
        "net = WineClassifier(input_size, hidden_size, output_size)\n",
        "#net = net.to(device) ## cast para a GPU\n",
        "net"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WineClassifier(\n",
              "  (hidden): Linear(in_features=13, out_features=32, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (out): Linear(in_features=32, out_features=3, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrAViVUVzCkj"
      },
      "source": [
        "# função objetivo Cross Entropy Loss:\n",
        "\n",
        "criterio = nn.CrossEntropyLoss()\n",
        "#criterio = criterio.to(device) ## cast para a gpu"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjtWPYvVdrXJ",
        "outputId": "658ad265-216b-4e4b-b1bf-1abf31c57706"
      },
      "source": [
        "# Transformação dos dados em tensores\n",
        "\n",
        "xtns = torch.from_numpy(dados).float() ## conversao para float32 ao invés do float64 padrao\n",
        "ytns = torch.from_numpy(labels)\n",
        "\n",
        "#xtns = xtns.to(device)\n",
        "#ytns = ytns.to(device)\n",
        "\n",
        "print(xtns.dtype)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvwKAh8Sd6_E",
        "outputId": "7c2a1f93-3605-4d57-c5c6-b5fb9fc6f880"
      },
      "source": [
        "previsao = net(xtns)\n",
        "print(\"Formato da saída com as 3 probabilidades softmax:\", previsao.shape)\n",
        "print(previsao)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato da saída com as 3 probabilidades softmax: torch.Size([178, 3])\n",
            "tensor([[1.0000e+00, 7.8278e-12, 0.0000e+00],\n",
            "        [1.0000e+00, 1.2428e-12, 0.0000e+00],\n",
            "        [1.0000e+00, 1.0712e-14, 0.0000e+00],\n",
            "        [1.0000e+00, 1.6125e-18, 0.0000e+00],\n",
            "        [1.0000e+00, 2.7223e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 4.3787e-18, 0.0000e+00],\n",
            "        [1.0000e+00, 1.9108e-16, 0.0000e+00],\n",
            "        [1.0000e+00, 1.5652e-15, 0.0000e+00],\n",
            "        [1.0000e+00, 1.0726e-12, 0.0000e+00],\n",
            "        [1.0000e+00, 1.2192e-12, 0.0000e+00],\n",
            "        [1.0000e+00, 2.1896e-19, 0.0000e+00],\n",
            "        [1.0000e+00, 2.5682e-16, 0.0000e+00],\n",
            "        [1.0000e+00, 3.9303e-17, 0.0000e+00],\n",
            "        [1.0000e+00, 1.8723e-14, 0.0000e+00],\n",
            "        [1.0000e+00, 6.3895e-20, 0.0000e+00],\n",
            "        [1.0000e+00, 5.2610e-16, 0.0000e+00],\n",
            "        [1.0000e+00, 2.6734e-15, 0.0000e+00],\n",
            "        [1.0000e+00, 3.1994e-13, 0.0000e+00],\n",
            "        [1.0000e+00, 1.2006e-21, 0.0000e+00],\n",
            "        [1.0000e+00, 5.1667e-09, 0.0000e+00],\n",
            "        [1.0000e+00, 1.4329e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 1.4001e-08, 0.0000e+00],\n",
            "        [1.0000e+00, 1.7256e-12, 0.0000e+00],\n",
            "        [1.0000e+00, 2.1273e-12, 0.0000e+00],\n",
            "        [1.0000e+00, 6.9907e-10, 0.0000e+00],\n",
            "        [1.0000e+00, 1.6459e-08, 0.0000e+00],\n",
            "        [1.0000e+00, 4.2363e-15, 0.0000e+00],\n",
            "        [1.0000e+00, 1.8804e-16, 0.0000e+00],\n",
            "        [1.0000e+00, 2.0346e-10, 0.0000e+00],\n",
            "        [1.0000e+00, 1.1588e-12, 0.0000e+00],\n",
            "        [1.0000e+00, 3.6744e-16, 0.0000e+00],\n",
            "        [1.0000e+00, 2.3336e-19, 0.0000e+00],\n",
            "        [1.0000e+00, 1.1653e-11, 0.0000e+00],\n",
            "        [1.0000e+00, 3.9747e-14, 0.0000e+00],\n",
            "        [1.0000e+00, 5.6686e-13, 0.0000e+00],\n",
            "        [1.0000e+00, 8.2796e-11, 0.0000e+00],\n",
            "        [1.0000e+00, 1.1480e-09, 0.0000e+00],\n",
            "        [1.0000e+00, 1.4563e-13, 0.0000e+00],\n",
            "        [1.0000e+00, 2.6925e-12, 0.0000e+00],\n",
            "        [1.0000e+00, 2.8752e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 3.7926e-08, 0.0000e+00],\n",
            "        [1.0000e+00, 4.9788e-13, 0.0000e+00],\n",
            "        [1.0000e+00, 2.8584e-13, 0.0000e+00],\n",
            "        [1.0000e+00, 3.6604e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 5.9567e-10, 0.0000e+00],\n",
            "        [1.0000e+00, 7.7776e-13, 0.0000e+00],\n",
            "        [1.0000e+00, 6.1808e-13, 0.0000e+00],\n",
            "        [1.0000e+00, 1.1785e-11, 0.0000e+00],\n",
            "        [1.0000e+00, 9.9251e-13, 0.0000e+00],\n",
            "        [1.0000e+00, 1.9243e-15, 0.0000e+00],\n",
            "        [1.0000e+00, 2.0131e-14, 0.0000e+00],\n",
            "        [1.0000e+00, 3.8056e-16, 0.0000e+00],\n",
            "        [1.0000e+00, 3.2671e-14, 0.0000e+00],\n",
            "        [1.0000e+00, 7.0173e-17, 0.0000e+00],\n",
            "        [1.0000e+00, 4.3421e-12, 0.0000e+00],\n",
            "        [1.0000e+00, 4.2260e-13, 0.0000e+00],\n",
            "        [1.0000e+00, 9.8438e-11, 0.0000e+00],\n",
            "        [1.0000e+00, 7.9419e-16, 0.0000e+00],\n",
            "        [1.0000e+00, 9.1056e-16, 0.0000e+00],\n",
            "        [9.9996e-01, 3.7985e-05, 6.8652e-38],\n",
            "        [1.0000e+00, 5.1697e-07, 0.0000e+00],\n",
            "        [9.9860e-01, 1.3995e-03, 7.0683e-32],\n",
            "        [1.0000e+00, 1.1804e-06, 0.0000e+00],\n",
            "        [9.9900e-01, 1.0040e-03, 1.9218e-30],\n",
            "        [9.5635e-01, 4.3653e-02, 5.2766e-24],\n",
            "        [1.0000e+00, 3.8640e-07, 0.0000e+00],\n",
            "        [9.9998e-01, 2.4097e-05, 1.2443e-37],\n",
            "        [9.9999e-01, 1.4864e-05, 2.6278e-38],\n",
            "        [1.0000e+00, 1.0639e-07, 0.0000e+00],\n",
            "        [9.9999e-01, 1.2207e-05, 0.0000e+00],\n",
            "        [1.0000e+00, 6.0993e-10, 0.0000e+00],\n",
            "        [9.9908e-01, 9.2103e-04, 7.9903e-30],\n",
            "        [9.9989e-01, 1.1314e-04, 1.1654e-34],\n",
            "        [1.0000e+00, 2.6558e-10, 0.0000e+00],\n",
            "        [1.0000e+00, 3.3412e-10, 0.0000e+00],\n",
            "        [9.9820e-01, 1.8028e-03, 3.1098e-30],\n",
            "        [9.9766e-01, 2.3446e-03, 3.8872e-28],\n",
            "        [9.9950e-01, 4.9734e-04, 4.4884e-35],\n",
            "        [1.0000e+00, 1.1413e-06, 0.0000e+00],\n",
            "        [9.9954e-01, 4.5530e-04, 5.6942e-33],\n",
            "        [9.0353e-01, 9.6466e-02, 5.2391e-19],\n",
            "        [1.0000e+00, 2.6449e-08, 0.0000e+00],\n",
            "        [1.0000e+00, 2.1278e-07, 0.0000e+00],\n",
            "        [9.9998e-01, 1.8028e-05, 4.0022e-38],\n",
            "        [9.9994e-01, 5.7176e-05, 5.1088e-38],\n",
            "        [9.9904e-01, 9.6338e-04, 5.0521e-32],\n",
            "        [9.9993e-01, 7.2051e-05, 3.0999e-36],\n",
            "        [9.9999e-01, 5.0393e-06, 6.3703e-42],\n",
            "        [1.0000e+00, 6.5757e-08, 0.0000e+00],\n",
            "        [1.0000e+00, 1.0828e-07, 0.0000e+00],\n",
            "        [9.9994e-01, 5.5628e-05, 1.9229e-35],\n",
            "        [9.9976e-01, 2.4019e-04, 6.6937e-33],\n",
            "        [9.9997e-01, 2.9285e-05, 8.3190e-37],\n",
            "        [9.3779e-01, 6.2206e-02, 1.0149e-19],\n",
            "        [9.6636e-01, 3.3641e-02, 1.5023e-23],\n",
            "        [1.0000e+00, 1.7040e-08, 0.0000e+00],\n",
            "        [9.9994e-01, 5.7617e-05, 6.7262e-44],\n",
            "        [9.9943e-01, 5.7019e-04, 4.8806e-31],\n",
            "        [1.0000e+00, 2.7591e-07, 0.0000e+00],\n",
            "        [9.9882e-01, 1.1809e-03, 4.2681e-29],\n",
            "        [1.0000e+00, 8.2179e-08, 0.0000e+00],\n",
            "        [9.9999e-01, 5.9424e-06, 1.1149e-41],\n",
            "        [9.9894e-01, 1.0600e-03, 4.0280e-31],\n",
            "        [9.9915e-01, 8.4732e-04, 7.2692e-30],\n",
            "        [1.0000e+00, 8.7063e-08, 0.0000e+00],\n",
            "        [9.7087e-01, 2.9127e-02, 9.4830e-22],\n",
            "        [9.9998e-01, 1.6347e-05, 4.3203e-38],\n",
            "        [9.9995e-01, 4.9389e-05, 4.3912e-36],\n",
            "        [9.4867e-01, 5.1328e-02, 2.4270e-21],\n",
            "        [1.0000e+00, 1.9868e-07, 0.0000e+00],\n",
            "        [9.9997e-01, 2.8785e-05, 1.6406e-40],\n",
            "        [9.7983e-01, 2.0171e-02, 1.5662e-22],\n",
            "        [9.9999e-01, 5.6660e-06, 1.8217e-44],\n",
            "        [9.9932e-01, 6.7770e-04, 1.9601e-31],\n",
            "        [9.9800e-01, 1.9960e-03, 8.5842e-28],\n",
            "        [9.9905e-01, 9.5229e-04, 1.7853e-29],\n",
            "        [9.9995e-01, 4.5407e-05, 1.8291e-36],\n",
            "        [9.3502e-01, 6.4978e-02, 4.4556e-23],\n",
            "        [9.9805e-01, 1.9457e-03, 1.3196e-26],\n",
            "        [1.0000e+00, 3.6503e-06, 8.5830e-42],\n",
            "        [1.0000e+00, 1.4353e-06, 0.0000e+00],\n",
            "        [9.9649e-01, 3.5069e-03, 1.3327e-32],\n",
            "        [9.8756e-01, 1.2436e-02, 5.1462e-25],\n",
            "        [9.9852e-01, 1.4777e-03, 4.8727e-27],\n",
            "        [9.9875e-01, 1.2532e-03, 1.9440e-27],\n",
            "        [9.9752e-01, 2.4822e-03, 4.0856e-27],\n",
            "        [9.9197e-01, 8.0278e-03, 4.7417e-25],\n",
            "        [9.9979e-01, 2.0795e-04, 5.9227e-34],\n",
            "        [9.8911e-01, 1.0893e-02, 4.2868e-24],\n",
            "        [1.0000e+00, 1.0549e-06, 1.5274e-43],\n",
            "        [9.9998e-01, 2.1048e-05, 5.6052e-45],\n",
            "        [9.9991e-01, 9.3326e-05, 4.6939e-38],\n",
            "        [9.9998e-01, 1.7886e-05, 5.4457e-41],\n",
            "        [9.9999e-01, 9.0505e-06, 1.5134e-43],\n",
            "        [1.0000e+00, 3.0945e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 1.3112e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 2.2594e-08, 0.0000e+00],\n",
            "        [9.9996e-01, 4.3822e-05, 2.4866e-37],\n",
            "        [1.0000e+00, 2.9809e-06, 4.6663e-43],\n",
            "        [9.9999e-01, 7.4833e-06, 3.5032e-43],\n",
            "        [1.0000e+00, 3.3913e-06, 3.0829e-44],\n",
            "        [1.0000e+00, 3.4353e-09, 0.0000e+00],\n",
            "        [9.9995e-01, 5.3857e-05, 9.9385e-38],\n",
            "        [9.9999e-01, 9.9349e-06, 2.6825e-40],\n",
            "        [1.0000e+00, 2.3545e-09, 0.0000e+00],\n",
            "        [1.0000e+00, 1.7564e-09, 0.0000e+00],\n",
            "        [9.9966e-01, 3.4363e-04, 4.5710e-30],\n",
            "        [1.0000e+00, 4.9086e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 4.5636e-07, 0.0000e+00],\n",
            "        [9.9989e-01, 1.0922e-04, 2.5571e-39],\n",
            "        [9.9833e-01, 1.6738e-03, 9.8011e-35],\n",
            "        [9.9859e-01, 1.4080e-03, 7.2194e-34],\n",
            "        [9.8708e-01, 1.2924e-02, 4.2006e-29],\n",
            "        [1.0000e+00, 3.8812e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 2.3246e-06, 0.0000e+00],\n",
            "        [1.0000e+00, 2.6771e-08, 0.0000e+00],\n",
            "        [9.9988e-01, 1.1731e-04, 4.6573e-35],\n",
            "        [1.0000e+00, 2.2294e-10, 0.0000e+00],\n",
            "        [1.0000e+00, 7.4719e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 1.3505e-06, 0.0000e+00],\n",
            "        [9.9997e-01, 2.7890e-05, 2.6806e-38],\n",
            "        [1.0000e+00, 6.4024e-07, 0.0000e+00],\n",
            "        [9.9998e-01, 2.4040e-05, 2.9412e-41],\n",
            "        [1.0000e+00, 6.7372e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 1.3019e-06, 0.0000e+00],\n",
            "        [9.9998e-01, 1.9948e-05, 2.6160e-38],\n",
            "        [1.0000e+00, 5.9059e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 9.9633e-08, 0.0000e+00],\n",
            "        [1.0000e+00, 4.8395e-08, 0.0000e+00],\n",
            "        [9.9999e-01, 4.9829e-06, 1.4013e-45],\n",
            "        [9.9992e-01, 8.3970e-05, 6.6185e-37],\n",
            "        [9.9983e-01, 1.6614e-04, 1.5846e-34],\n",
            "        [1.0000e+00, 3.4162e-07, 0.0000e+00],\n",
            "        [1.0000e+00, 1.8725e-08, 0.0000e+00],\n",
            "        [1.0000e+00, 3.0882e-08, 0.0000e+00],\n",
            "        [1.0000e+00, 1.0309e-08, 0.0000e+00],\n",
            "        [1.0000e+00, 1.0562e-08, 0.0000e+00],\n",
            "        [9.9999e-01, 1.3230e-05, 3.2569e-41]], grad_fn=<SoftmaxBackward>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5akjD3nTefvD",
        "outputId": "754eb956-ecc8-424c-bda6-a117b37f42b1"
      },
      "source": [
        "perda = criterio(previsao, ytns)\n",
        "print(\"Média de perda nas previsoes:\", perda.data)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média de perda nas previsoes: tensor(1.2165)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dJ99KhyhuCI"
      },
      "source": [
        "### Função de perda/objetivo para Regressão\n",
        "\n",
        "#### Preparação dos dados e da rede neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxGL755DhLK4",
        "outputId": "80be5f94-8e9e-4561-8f16-951b41f1b7ef"
      },
      "source": [
        "# definição dos dados\n",
        "# dataset de diabetes do sklearn\n",
        "\n",
        "diabetes = datasets.load_diabetes()\n",
        "\n",
        "dados = diabetes.data\n",
        "labels = diabetes.target\n",
        "\n",
        "dados_nomes = diabetes.feature_names\n",
        "\n",
        "print(\"Formato dados:\", dados.shape)\n",
        "print(\"Formato labels:\", labels.shape)\n",
        "print(\"Features:\", dados_nomes)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato dados: (442, 10)\n",
            "Formato labels: (442,)\n",
            "Features: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2is7oyLyj6d-",
        "outputId": "52eb6c37-068d-491b-e499-74249ddc7f0f"
      },
      "source": [
        "diabetes_df = pd.DataFrame(data=dados, columns=dados_nomes)\n",
        "diabetes_df.head()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>-0.043401</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.019908</td>\n",
              "      <td>-0.017646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>0.074412</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.068330</td>\n",
              "      <td>-0.092204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005671</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>-0.032356</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.089063</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>-0.036038</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>-0.009362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.031991</td>\n",
              "      <td>-0.046641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        age       sex       bmi  ...        s4        s5        s6\n",
              "0  0.038076  0.050680  0.061696  ... -0.002592  0.019908 -0.017646\n",
              "1 -0.001882 -0.044642 -0.051474  ... -0.039493 -0.068330 -0.092204\n",
              "2  0.085299  0.050680  0.044451  ... -0.002592  0.002864 -0.025930\n",
              "3 -0.089063 -0.044642 -0.011595  ...  0.034309  0.022692 -0.009362\n",
              "4  0.005383 -0.044642 -0.036385  ... -0.002592 -0.031991 -0.046641\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wiA5UX-kzcs"
      },
      "source": [
        "# Definição da rede neural\n",
        "\n",
        "class DiabetesRegressor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, out_size):\n",
        "        super(DiabetesRegressor, self).__init__()\n",
        "        self.hidden = nn.Linear(input_size, hidden_size)    ## Camada hidden com \n",
        "        self.relu = nn.ReLU()                               ## Ativação ReLU\n",
        "        self.out = nn.Linear(hidden_size, out_size)         ## Saída linear\n",
        "        self.softmax = nn.Softmax()                         ## softmax para transformar em probabilidades\n",
        "\n",
        "    def forward(self, dados):\n",
        "        feature = self.relu(self.hidden(dados))     ## feature é a ativação ReLU da camada hidden\n",
        "        output = self.softmax(self.out(feature))    ## softmax da camada de saída recebendo feature\n",
        "        return output"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht3jezralX8o",
        "outputId": "0a205dab-3126-46e5-b64d-58d08a99d889"
      },
      "source": [
        "input_size = dados.shape[1]     ## quantidade de features do dataset\n",
        "hidden_size = 32                ## quantidade julgada necessária para o problema (hiperparametro)\n",
        "output_size = 1                 ## dimensão da saída (progressão da diabetes)\n",
        "\n",
        "print(\"Input_size:\", input_size)\n",
        "print(\"Hidden_size:\", hidden_size)\n",
        "print(\"Output_size:\", output_size)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input_size: 10\n",
            "Hidden_size: 32\n",
            "Output_size: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1nbEPMVlmjd",
        "outputId": "334e1d17-cc31-4981-e6c2-f6ad2e1f6893"
      },
      "source": [
        "# Criação da rede:\n",
        "\n",
        "net = DiabetesRegressor(input_size, hidden_size, output_size)\n",
        "#net = net.to(device) ## cast para a GPU\n",
        "net"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DiabetesRegressor(\n",
              "  (hidden): Linear(in_features=10, out_features=32, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYXRE7o_mE0d"
      },
      "source": [
        "# função objetivo MSE Loss:\n",
        "\n",
        "criterio = nn.MSELoss()"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zv0F70-mxcj",
        "outputId": "f274b882-b8de-471a-e195-7bd5bf019d00"
      },
      "source": [
        "# Transformação dos dados em tensores\n",
        "\n",
        "xtns = torch.from_numpy(dados).float() ## conversao para float32 ao invés do float64 padrao\n",
        "ytns = torch.from_numpy(labels).float()\n",
        "\n",
        "print(xtns.shape, ytns.shape)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([442, 10]) torch.Size([442])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR4nv9zAm0AP",
        "outputId": "687f0867-2e27-4dd7-85ea-166c02b118e8"
      },
      "source": [
        "previsoes = net(xtns)\n",
        "\n",
        "# para a função MSELoss os dados e labels devem\n",
        "# ter a mesma dimensionalidade, então fazemos um squeeze \n",
        "# nas previsoes para retirar uma dimensao e ficar igual\n",
        "# ao ytns\n",
        "perda = criterio(previsoes.squeeze(), ytns)\n",
        "print(\"Média da distância quadrática entre o dado e o label:\", perda.data)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média da distância quadrática entre o dado e o label: tensor(28771.2148)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRtsBKbbqqUO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}